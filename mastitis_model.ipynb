{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/clinical_mastitis_cows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jersey      6498\n",
       "hostlene     102\n",
       "Name: Breed, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cow_ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Months after giving birth</th>\n",
       "      <th>Previous_Mastits_status</th>\n",
       "      <th>IUFL</th>\n",
       "      <th>EUFL</th>\n",
       "      <th>IUFR</th>\n",
       "      <th>EUFR</th>\n",
       "      <th>IURL</th>\n",
       "      <th>EURL</th>\n",
       "      <th>IURR</th>\n",
       "      <th>EURR</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Pain</th>\n",
       "      <th>Milk_visibility</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cow1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>180</td>\n",
       "      <td>150</td>\n",
       "      <td>180</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cow1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>180</td>\n",
       "      <td>152</td>\n",
       "      <td>185</td>\n",
       "      <td>151</td>\n",
       "      <td>180</td>\n",
       "      <td>152</td>\n",
       "      <td>181</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cow1</td>\n",
       "      <td>3</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>182</td>\n",
       "      <td>153</td>\n",
       "      <td>186</td>\n",
       "      <td>151</td>\n",
       "      <td>186</td>\n",
       "      <td>153</td>\n",
       "      <td>183</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cow1</td>\n",
       "      <td>4</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>183</td>\n",
       "      <td>155</td>\n",
       "      <td>189</td>\n",
       "      <td>155</td>\n",
       "      <td>182</td>\n",
       "      <td>155</td>\n",
       "      <td>186</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cow1</td>\n",
       "      <td>5</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>186</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>185</td>\n",
       "      <td>150</td>\n",
       "      <td>188</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cow1</td>\n",
       "      <td>6</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>182</td>\n",
       "      <td>152</td>\n",
       "      <td>182</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>152</td>\n",
       "      <td>181</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cow_ID  Day   Breed  Months after giving birth  Previous_Mastits_status  \\\n",
       "0   cow1    1  Jersey                          1                        0   \n",
       "1   cow1    2  Jersey                          1                        0   \n",
       "2   cow1    3  Jersey                          1                        0   \n",
       "3   cow1    4  Jersey                          1                        0   \n",
       "4   cow1    5  Jersey                          1                        0   \n",
       "5   cow1    6  Jersey                          1                        0   \n",
       "\n",
       "   IUFL  EUFL  IUFR  EUFR  IURL  EURL  IURR  EURR  Temperature  Hardness  \\\n",
       "0   150   180   150   180   150   181   150   181           43         0   \n",
       "1   152   180   152   185   151   180   152   181           42         0   \n",
       "2   152   182   153   186   151   186   153   183           41         0   \n",
       "3   155   183   155   189   155   182   155   186           40         0   \n",
       "4   150   186   150   181   150   185   150   188           41         0   \n",
       "5   152   182   152   182   150   181   152   181           40         0   \n",
       "\n",
       "   Pain  Milk_visibility  class1  \n",
       "0     0                0       0  \n",
       "1     0                0       0  \n",
       "2     0                0       0  \n",
       "3     0                0       0  \n",
       "4     0                0       0  \n",
       "5     0                0       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏµúÏ¢Ö Î≥ÄÏàò Í∞úÏàò: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUFL_mean</th>\n",
       "      <th>EUFL_mean</th>\n",
       "      <th>IUFR_mean</th>\n",
       "      <th>EUFR_mean</th>\n",
       "      <th>IURL_mean</th>\n",
       "      <th>EURL_mean</th>\n",
       "      <th>IURR_mean</th>\n",
       "      <th>EURR_mean</th>\n",
       "      <th>Temperature_mean</th>\n",
       "      <th>IUFL_range</th>\n",
       "      <th>EUFL_range</th>\n",
       "      <th>IUFR_range</th>\n",
       "      <th>EUFR_range</th>\n",
       "      <th>IURL_range</th>\n",
       "      <th>EURL_range</th>\n",
       "      <th>IURR_range</th>\n",
       "      <th>EURR_range</th>\n",
       "      <th>Temperature_range</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cow_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cow1</th>\n",
       "      <td>151.833333</td>\n",
       "      <td>182.166667</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>183.833333</td>\n",
       "      <td>151.166667</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>183.333333</td>\n",
       "      <td>41.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow2</th>\n",
       "      <td>237.833333</td>\n",
       "      <td>275.500000</td>\n",
       "      <td>233.500000</td>\n",
       "      <td>276.166667</td>\n",
       "      <td>234.333333</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>238.666667</td>\n",
       "      <td>277.333333</td>\n",
       "      <td>40.833333</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow3</th>\n",
       "      <td>238.833333</td>\n",
       "      <td>276.500000</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>277.166667</td>\n",
       "      <td>235.333333</td>\n",
       "      <td>280.500000</td>\n",
       "      <td>239.666667</td>\n",
       "      <td>278.333333</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow4</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>185.500000</td>\n",
       "      <td>215.833333</td>\n",
       "      <td>183.833333</td>\n",
       "      <td>211.333333</td>\n",
       "      <td>185.666667</td>\n",
       "      <td>213.666667</td>\n",
       "      <td>41.166667</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow5</th>\n",
       "      <td>154.333333</td>\n",
       "      <td>184.833333</td>\n",
       "      <td>154.333333</td>\n",
       "      <td>188.166667</td>\n",
       "      <td>156.833333</td>\n",
       "      <td>183.833333</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>184.666667</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IUFL_mean   EUFL_mean   IUFR_mean   EUFR_mean   IURL_mean  \\\n",
       "Cow_ID                                                               \n",
       "cow1    151.833333  182.166667  152.000000  183.833333  151.166667   \n",
       "cow2    237.833333  275.500000  233.500000  276.166667  234.333333   \n",
       "cow3    238.833333  276.500000  234.500000  277.166667  235.333333   \n",
       "cow4    183.333333  211.500000  185.500000  215.833333  183.833333   \n",
       "cow5    154.333333  184.833333  154.333333  188.166667  156.833333   \n",
       "\n",
       "         EURL_mean   IURR_mean   EURR_mean  Temperature_mean  IUFL_range  \\\n",
       "Cow_ID                                                                     \n",
       "cow1    182.500000  152.000000  183.333333         41.166667           5   \n",
       "cow2    279.500000  238.666667  277.333333         40.833333          15   \n",
       "cow3    280.500000  239.666667  278.333333         42.166667          15   \n",
       "cow4    211.333333  185.666667  213.666667         41.166667           7   \n",
       "cow5    183.833333  154.000000  184.666667         42.666667           8   \n",
       "\n",
       "        EUFL_range  IUFR_range  EUFR_range  IURL_range  EURL_range  \\\n",
       "Cow_ID                                                               \n",
       "cow1             6           5           9           5           6   \n",
       "cow2            11          10          13          15          17   \n",
       "cow3            11          10          13          15          17   \n",
       "cow4             6           8           8           6           5   \n",
       "cow5             9           9           9          10           7   \n",
       "\n",
       "        IURR_range  EURR_range  Temperature_range  class1  \n",
       "Cow_ID                                                     \n",
       "cow1             5           7                  3       0  \n",
       "cow2            20          10                  3       1  \n",
       "cow3            20          10                  6       1  \n",
       "cow4            10           5                  2       0  \n",
       "cow5            10           8                  5       1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changing_ids = ['cow10']\n",
    "\n",
    "# ÏÇ¨Ïö©Ìï† Ïª¨Îüº\n",
    "cols = ['Cow_ID', 'Day', 'IUFL', 'EUFL', 'IUFR', 'EUFR', \n",
    "        'IURL', 'EURL', 'IURR', 'EURR', 'Temperature', 'class1']\n",
    "\n",
    "# Î≥ÄÌôîÌïú Í∞úÏ≤¥ Ï†úÍ±∞\n",
    "df_filtered = df[\n",
    "    (~df['Cow_ID'].isin(changing_ids)) &\n",
    "    (df['Breed'] != 'hostlene')\n",
    "][cols].copy()\n",
    "\n",
    "# ÌèâÍ∑†Í≥º Î≤îÏúÑ Í≥ÑÏÇ∞ ÎåÄÏÉÅ Ïª¨Îüº\n",
    "value_cols = ['IUFL', 'EUFL', 'IUFR', 'EUFR', \n",
    "              'IURL', 'EURL', 'IURR', 'EURR', 'Temperature']\n",
    "\n",
    "# (1) ÌèâÍ∑† Í≥ÑÏÇ∞\n",
    "mean_df = df_filtered.groupby('Cow_ID')[value_cols].mean()\n",
    "mean_df.columns = [f\"{col}_mean\" for col in mean_df.columns]\n",
    "\n",
    "# (2) Î≤îÏúÑ (ÏµúÎåÄ - ÏµúÏÜå) Í≥ÑÏÇ∞\n",
    "range_df = (\n",
    "    df_filtered.groupby('Cow_ID')[value_cols].max()\n",
    "    - df_filtered.groupby('Cow_ID')[value_cols].min()\n",
    ")\n",
    "range_df.columns = [f\"{col}_range\" for col in range_df.columns]\n",
    "\n",
    "# (3) class1ÏùÄ ÎßàÏßÄÎßâ ÎÇ†Ïßú Í∏∞Ï§Ä\n",
    "class_df = (\n",
    "    df_filtered.sort_values(['Cow_ID', 'Day'])\n",
    "               .groupby('Cow_ID')['class1']\n",
    "               .last()\n",
    ")\n",
    "\n",
    "# (4) Î≥ëÌï©\n",
    "final_df = pd.concat([mean_df, range_df], axis=1)\n",
    "final_df['class1'] = class_df\n",
    "\n",
    "# Ï†ïÎ†¨ Î∞è Ïù∏Îç±Ïä§ Ï†ïÎ¶¨\n",
    "final_df = final_df.reset_index()\n",
    "final_df['Cow_ID_num'] = final_df['Cow_ID'].str.extract('(\\d+)').astype(int)\n",
    "final_df = final_df.sort_values('Cow_ID_num').drop(columns='Cow_ID_num')\n",
    "final_df = final_df.set_index('Cow_ID')\n",
    "\n",
    "# Í≤∞Í≥º ÌôïÏù∏\n",
    "print(f\"ÏµúÏ¢Ö Î≥ÄÏàò Í∞úÏàò: {final_df.shape[1]}\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082, 19)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ train_normal: 400\n",
      "‚úÖ val_normal: 100, val_abnormal: 100\n",
      "‚úÖ test_normal: 100, test_abnormal: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï\n",
    "seed = 42\n",
    "\n",
    "# class1 Í∏∞Ï§Ä Î∂ÑÎ¶¨\n",
    "normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "# Ï†ïÏÉÅ: 400 train / 100 val / 100 test\n",
    "train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "remaining_for_test = remaining_normal.drop(val_normal.index)\n",
    "test_normal = remaining_for_test.sample(n=100, random_state=seed)\n",
    "\n",
    "# ÎπÑÏ†ïÏÉÅ: 100 val / 100 test\n",
    "val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "# ÌôïÏù∏\n",
    "print(f\"‚úÖ train_normal: {len(train_normal)}\")\n",
    "print(f\"‚úÖ val_normal: {len(val_normal)}, val_abnormal: {len(val_abnormal)}\")\n",
    "print(f\"‚úÖ test_normal: {len(test_normal)}, test_abnormal: {len(test_abnormal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# DataFrame to Tensor Î≥ÄÌôò Ìï®Ïàò\n",
    "def to_tensor(df):\n",
    "    return torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "# ÌÖêÏÑúÎ°ú Î≥ÄÌôò\n",
    "X_train = to_tensor(train_normal)\n",
    "X_val_normal = to_tensor(val_normal)\n",
    "X_val_abnormal = to_tensor(val_abnormal)\n",
    "X_test_normal = to_tensor(test_normal)\n",
    "X_test_abnormal = to_tensor(test_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32989\n",
      "üìå Confusion Matrix (Í∏∞Ï§Ä: Ïã§Ï†ú=Ìñâ, ÏòàÏ∏°=Ïó¥, class=1 ÎπÑÏ†ïÏÉÅ Í∏∞Ï§Ä)\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "Precision: 0.9796\n",
      "Recall:    0.9600\n",
      "F1 Score:  0.9697\n",
      "Accuracy:  0.9700\n",
      "Best Threshold by F1: 81.600266\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=14):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
    "model = AutoEncoder(input_dim=18)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ÌïôÏäµ ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "n_epochs = 100000\n",
    "patience = 10000\n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "# ÌïôÏäµ Î£®ÌîÑ\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # early stoppingÏö© Í≤ÄÏ¶ù Î°úÏä§\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val_normal)\n",
    "        val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# ÏµúÏ†Å Î™®Îç∏ Î°úÎìú\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ïû¨Íµ¨ÏÑ± Ïò§Ï∞®\n",
    "recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "y_val_true = torch.cat([\n",
    "    torch.zeros_like(recon_val_normal),\n",
    "    torch.ones_like(recon_val_abnormal)\n",
    "])\n",
    "\n",
    "# F1 Í∏∞Ï§Ä ÏµúÏ†Å ÏûÑÍ≥ÑÍ∞í Ï∞æÍ∏∞\n",
    "thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "best_f1 = 0\n",
    "best_threshold = None\n",
    "for t in thresholds:\n",
    "    y_pred = (recon_val_all >= t).int()\n",
    "    f1 = f1_score(y_val_true.numpy(), y_pred.numpy())\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÌèâÍ∞Ä\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "y_test_true = torch.cat([\n",
    "    torch.zeros_like(recon_test_normal),\n",
    "    torch.ones_like(recon_test_abnormal)\n",
    "])\n",
    "y_test_pred = (recon_test_all >= best_threshold).int()\n",
    "\n",
    "# ÌèâÍ∞Ä ÏßÄÌëú Í≥ÑÏÇ∞ (ÎπÑÏ†ïÏÉÅ class=1ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú)\n",
    "cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "accuracy = accuracy_score(y_test_true, y_test_pred)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"üìå Confusion Matrix (Í∏∞Ï§Ä: Ïã§Ï†ú=Ìñâ, ÏòàÏ∏°=Ïó¥, class=1 ÎπÑÏ†ïÏÉÅ Í∏∞Ï§Ä)\")\n",
    "print(cm)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Best Threshold by F1: {best_threshold:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23696\n",
      "üìå Confusion Matrix (Í∏∞Ï§Ä: Ïã§Ï†ú=Ìñâ, ÏòàÏ∏°=Ïó¥, class=1 ÎπÑÏ†ïÏÉÅ Í∏∞Ï§Ä)\n",
      "[[64 36]\n",
      " [ 4 96]]\n",
      "Precision: 0.7273\n",
      "Recall:    0.9600\n",
      "F2 Score:  0.9023\n",
      "Accuracy:  0.8000\n",
      "Best Threshold by F2: 87.064911\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "seed = 45\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=7):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
    "model = AutoEncoder(input_dim=18)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ÌïôÏäµ ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "n_epochs = 100000\n",
    "patience = 10000\n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "# ÌïôÏäµ Î£®ÌîÑ\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # early stoppingÏö© Í≤ÄÏ¶ù Î°úÏä§\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val_normal)\n",
    "        val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# ÏµúÏ†Å Î™®Îç∏ Î°úÎìú\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ïû¨Íµ¨ÏÑ± Ïò§Ï∞®\n",
    "recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "y_val_true = torch.cat([\n",
    "    torch.zeros_like(recon_val_normal),\n",
    "    torch.ones_like(recon_val_abnormal)\n",
    "])\n",
    "\n",
    "# F2 Í∏∞Ï§Ä ÏµúÏ†Å ÏûÑÍ≥ÑÍ∞í Ï∞æÍ∏∞\n",
    "thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "best_f2 = 0\n",
    "best_threshold = None\n",
    "for t in thresholds:\n",
    "    y_pred = (recon_val_all >= t).int()\n",
    "    f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "    if f2 > best_f2:\n",
    "        best_f2 = f2\n",
    "        best_threshold = t\n",
    "\n",
    "# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÌèâÍ∞Ä\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "y_test_true = torch.cat([\n",
    "    torch.zeros_like(recon_test_normal),\n",
    "    torch.ones_like(recon_test_abnormal)\n",
    "])\n",
    "y_test_pred = (recon_test_all >= best_threshold).int()\n",
    "\n",
    "# ÌèâÍ∞Ä ÏßÄÌëú Í≥ÑÏÇ∞ (ÎπÑÏ†ïÏÉÅ class=1ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú)\n",
    "cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "accuracy = accuracy_score(y_test_true, y_test_pred)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"üìå Confusion Matrix (Í∏∞Ï§Ä: Ïã§Ï†ú=Ìñâ, ÏòàÏ∏°=Ïó¥, class=1 ÎπÑÏ†ïÏÉÅ Í∏∞Ï§Ä)\")\n",
    "print(cm)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F2 Score:  {fbeta_score(y_test_true.numpy(), y_test_pred.numpy(), beta=2):.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Best Threshold by F2: {best_threshold:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7/2 ÌîºÎìúÎ∞±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[96  4]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[89 11]\n",
      " [13 87]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[96  4]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [16 84]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[96  4]\n",
      " [19 81]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[100   0]\n",
      " [ 10  90]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[92  8]\n",
      " [16 84]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[98  2]\n",
      " [19 81]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[89 11]\n",
      " [13 87]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[96  4]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[93  7]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[99  1]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[96  4]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[96  4]\n",
      " [19 81]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[98  2]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[98  2]\n",
      " [19 81]]\n",
      "\n",
      "üìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.949767   0.896  0.921953  0.906171     0.924\n",
      "1           4      0.3   0.960317   0.876  0.915946  0.891494     0.920\n",
      "2           4      0.4   0.964239   0.866  0.912021  0.883743     0.917\n",
      "3           4      0.5   0.962550   0.862  0.909041  0.880126     0.914\n",
      "4           7      0.2   0.951847   0.896  0.922913  0.906538     0.925\n",
      "5           7      0.3   0.956543   0.886  0.919798  0.899190     0.923\n",
      "6           7      0.4   0.967053   0.878  0.919904  0.894197     0.924\n",
      "7           7      0.5   0.971282   0.872  0.918381  0.889859     0.923\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï Ìï®Ïàò\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû• Î¶¨Ïä§Ìä∏\n",
    "all_results = []\n",
    "\n",
    "# Ïã§Ìóò Ï°∞Ìï© Î∞òÎ≥µ\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # ÌÖêÏÑú Î≥ÄÌôò\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # Î™®Îç∏ Ï†ïÏùò\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "            trigger = 0\n",
    "\n",
    "            # ÌïôÏäµ\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Í≤ÄÏ¶ù\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold ÌÉêÏÉâ\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # ÌÖåÏä§Ìä∏\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # ÌèâÍ∑† Ï†ÄÏû•\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\nüìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÏòàÏ∏°Îêú Ïù¥ÏÉÅÏπò Ïàò: 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUFL_mean</th>\n",
       "      <th>EUFL_mean</th>\n",
       "      <th>IUFR_mean</th>\n",
       "      <th>EUFR_mean</th>\n",
       "      <th>IURL_mean</th>\n",
       "      <th>EURL_mean</th>\n",
       "      <th>IURR_mean</th>\n",
       "      <th>EURR_mean</th>\n",
       "      <th>Temperature_mean</th>\n",
       "      <th>IUFL_range</th>\n",
       "      <th>...</th>\n",
       "      <th>IUFR_range</th>\n",
       "      <th>EUFR_range</th>\n",
       "      <th>IURL_range</th>\n",
       "      <th>EURL_range</th>\n",
       "      <th>IURR_range</th>\n",
       "      <th>EURR_range</th>\n",
       "      <th>Temperature_range</th>\n",
       "      <th>recon_error</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>235.666667</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>234.166667</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>263.666667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3138.750977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>263.666667</td>\n",
       "      <td>297.666667</td>\n",
       "      <td>263.666667</td>\n",
       "      <td>295.166667</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>297.666667</td>\n",
       "      <td>263.333333</td>\n",
       "      <td>297.333333</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3697.348633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>235.500000</td>\n",
       "      <td>276.833333</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>235.333333</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>237.666667</td>\n",
       "      <td>277.333333</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4968.123047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>186.833333</td>\n",
       "      <td>305.833333</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>153.833333</td>\n",
       "      <td>185.333333</td>\n",
       "      <td>154.500000</td>\n",
       "      <td>185.333333</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4575.005859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>237.333333</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>356.166667</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>275.833333</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>49.833333</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4994.061523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>309.166667</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>240.666667</td>\n",
       "      <td>282.833333</td>\n",
       "      <td>239.500000</td>\n",
       "      <td>281.833333</td>\n",
       "      <td>241.166667</td>\n",
       "      <td>279.833333</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4238.732422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>305.833333</td>\n",
       "      <td>357.333333</td>\n",
       "      <td>260.333333</td>\n",
       "      <td>283.166667</td>\n",
       "      <td>260.500000</td>\n",
       "      <td>281.166667</td>\n",
       "      <td>258.500000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5531.837402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>302.666667</td>\n",
       "      <td>356.833333</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>277.166667</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>275.833333</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>276.333333</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5160.001953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>239.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>240.333333</td>\n",
       "      <td>278.833333</td>\n",
       "      <td>308.666667</td>\n",
       "      <td>356.666667</td>\n",
       "      <td>237.666667</td>\n",
       "      <td>277.166667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3926.436523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>230.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>231.333333</td>\n",
       "      <td>269.833333</td>\n",
       "      <td>299.666667</td>\n",
       "      <td>347.666667</td>\n",
       "      <td>228.666667</td>\n",
       "      <td>268.166667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3581.935303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IUFL_mean   EUFL_mean   IUFR_mean   EUFR_mean   IURL_mean   EURL_mean  \\\n",
       "44   235.666667  267.000000  236.000000  264.500000  234.166667  265.000000   \n",
       "46   263.666667  297.666667  263.666667  295.166667  262.000000  297.666667   \n",
       "101  235.500000  276.833333  306.000000  356.000000  235.333333  276.000000   \n",
       "103  154.000000  186.833333  305.833333  358.000000  153.833333  185.333333   \n",
       "104  237.333333  276.000000  307.666667  356.166667  234.500000  275.833333   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "194  309.166667  360.000000  240.666667  282.833333  239.500000  281.833333   \n",
       "195  305.833333  357.333333  260.333333  283.166667  260.500000  281.166667   \n",
       "196  302.666667  356.833333  236.500000  277.166667  236.500000  275.833333   \n",
       "198  239.000000  276.000000  240.333333  278.833333  308.666667  356.666667   \n",
       "199  230.000000  267.000000  231.333333  269.833333  299.666667  347.666667   \n",
       "\n",
       "      IURR_mean   EURR_mean  Temperature_mean  IUFL_range  ...  IUFR_range  \\\n",
       "44   124.500000  263.666667         43.000000          10  ...           9   \n",
       "46   263.333333  297.333333         43.000000           9  ...           6   \n",
       "101  237.666667  277.333333         50.000000          10  ...           9   \n",
       "103  154.500000  185.333333         49.000000           7  ...          10   \n",
       "104  238.000000  279.000000         49.833333          10  ...          10   \n",
       "..          ...         ...               ...         ...  ...         ...   \n",
       "194  241.166667  279.833333         43.000000           7  ...          10   \n",
       "195  258.500000  282.000000         55.500000          10  ...           8   \n",
       "196  234.500000  276.333333         56.000000           6  ...           8   \n",
       "198  237.666667  277.166667         43.000000          10  ...          10   \n",
       "199  228.666667  268.166667         43.000000          10  ...          10   \n",
       "\n",
       "     EUFR_range  IURL_range  EURL_range  IURR_range  EURR_range  \\\n",
       "44            5          10           8           8           7   \n",
       "46            6           6           9           9          10   \n",
       "101           8          10           8           7           8   \n",
       "103           9          10           5           8           7   \n",
       "104           7           6           7          10          10   \n",
       "..          ...         ...         ...         ...         ...   \n",
       "194           9          10           9          10           6   \n",
       "195           9           9           9          10          10   \n",
       "196          10          10           8           3           9   \n",
       "198           8           9          10          10          10   \n",
       "199           8           9          10          10          10   \n",
       "\n",
       "     Temperature_range  recon_error  true_label  pred_label  \n",
       "44                   0  3138.750977         0.0           1  \n",
       "46                   0  3697.348633         0.0           1  \n",
       "101                  0  4968.123047         1.0           1  \n",
       "103                  0  4575.005859         1.0           1  \n",
       "104                  1  4994.061523         1.0           1  \n",
       "..                 ...          ...         ...         ...  \n",
       "194                  0  4238.732422         1.0           1  \n",
       "195                  2  5531.837402         1.0           1  \n",
       "196                  0  5160.001953         1.0           1  \n",
       "198                  0  3926.436523         1.0           1  \n",
       "199                  0  3581.935303         1.0           1  \n",
       "\n",
       "[83 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ÌÖåÏä§Ìä∏ Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "\n",
    "# Ïã§Ï†ú ÎùºÎ≤®\n",
    "y_test_true = torch.cat([\n",
    "    torch.zeros_like(recon_test_normal),\n",
    "    torch.ones_like(recon_test_abnormal)\n",
    "])\n",
    "\n",
    "# Ï†ÑÏ≤¥ ÌÖåÏä§Ìä∏ Ïû¨Íµ¨ÏÑ±Ïò§Ï∞®\n",
    "recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "# Ï†ÑÏ≤¥ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Íµ¨ÏÑ±\n",
    "test_all_df = pd.concat([test_normal, test_abnormal], axis=0).reset_index(drop=True)\n",
    "test_all_df['recon_error'] = recon_test_all.cpu().numpy()\n",
    "test_all_df['true_label'] = y_test_true.cpu().numpy()\n",
    "test_all_df['pred_label'] = y_test_pred.cpu().numpy()\n",
    "\n",
    "# ‚úÖ Ïù¥ÏÉÅÏπòÎ°ú ÏòàÏ∏°Îêú ÏºÄÏù¥Ïä§Îßå Î≥¥Í∏∞\n",
    "anomalies = test_all_df[test_all_df['pred_label'] == 1]\n",
    "print(f\"\\nÏòàÏ∏°Îêú Ïù¥ÏÉÅÏπò Ïàò: {len(anomalies)}\")\n",
    "display(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[69 31]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[71 29]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[69 31]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[90 10]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[72 28]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[46 54]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[76 24]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[49 51]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[42 58]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[76 24]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[55 45]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[89 11]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[91  9]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[95  5]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[69 31]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[95  5]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[92  8]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[90 10]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[44 56]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[46 54]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[90 10]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "üìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.790932   0.940  0.845848  0.894903     0.806\n",
      "1           4      0.3   0.777039   0.932  0.835756  0.886310     0.796\n",
      "2           4      0.4   0.712237   0.948  0.801026  0.878658     0.744\n",
      "3           4      0.5   0.710910   0.932  0.792787  0.865965     0.737\n",
      "4           7      0.2   0.846395   0.942  0.877643  0.909670     0.845\n",
      "5           7      0.3   0.832068   0.940  0.868068  0.904262     0.832\n",
      "6           7      0.4   0.789624   0.952  0.848944  0.902495     0.805\n",
      "7           7      0.5   0.729367   0.936  0.803022  0.871979     0.747\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï Ìï®Ïàò\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû• Î¶¨Ïä§Ìä∏\n",
    "all_results = []\n",
    "\n",
    "# Ïã§Ìóò Ï°∞Ìï© Î∞òÎ≥µ\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # ÌÖêÏÑú Î≥ÄÌôò\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # Î™®Îç∏ Ï†ïÏùò\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "            trigger = 0\n",
    "\n",
    "            # ÌïôÏäµ\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Í≤ÄÏ¶ù\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold ÌÉêÏÉâ\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # ÌÖåÏä§Ìä∏\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # ÌèâÍ∑† Ï†ÄÏû•\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\nüìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[92  8]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[93  7]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[97  3]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[91  9]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[98  2]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[35 65]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[95  5]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[91  9]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[95  5]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[95  5]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[92  8]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[87 13]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "üìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.946889   0.890  0.917297  0.900663     0.920\n",
      "1           4      0.3   0.951614   0.868  0.907728  0.883434     0.912\n",
      "2           4      0.4   0.933584   0.874  0.902650  0.885204     0.906\n",
      "3           4      0.5   0.764277   0.942  0.830876  0.890141     0.792\n",
      "4           7      0.2   0.951768   0.902  0.925683  0.911206     0.928\n",
      "5           7      0.3   0.895404   0.900  0.890064  0.893682     0.880\n",
      "6           7      0.4   0.882445   0.884  0.875693  0.878352     0.866\n",
      "7           7      0.5   0.811183   0.928  0.856323  0.895013     0.835\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï Ìï®Ïàò\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû• Î¶¨Ïä§Ìä∏\n",
    "all_results = []\n",
    "\n",
    "# Ïã§Ìóò Ï°∞Ìï© Î∞òÎ≥µ\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # ÌÖêÏÑú Î≥ÄÌôò\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # Î™®Îç∏ Ï†ïÏùò\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "        \n",
    "            trigger = 0\n",
    "\n",
    "            # ÌïôÏäµ\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Í≤ÄÏ¶ù\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold ÌÉêÏÉâ\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # ÌÖåÏä§Ìä∏\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # ÌèâÍ∑† Ï†ÄÏû•\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\nüìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[94  6]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[45 55]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[38 62]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[92  8]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[94  6]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[39 61]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[46 54]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[93  7]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[95  5]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[45 55]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[91  9]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[35 65]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[82 18]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[90 10]\n",
      " [17 83]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [18 82]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "üìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.805608   0.916  0.846373  0.883406     0.821\n",
      "1           4      0.3   0.811602   0.906  0.843593  0.876100     0.820\n",
      "2           4      0.4   0.806275   0.904  0.842358  0.875228     0.821\n",
      "3           4      0.5   0.696009   0.958  0.798725  0.884865     0.748\n",
      "4           7      0.2   0.869999   0.902  0.878830  0.890486     0.867\n",
      "5           7      0.3   0.810789   0.898  0.839841  0.870051     0.817\n",
      "6           7      0.4   0.815661   0.892  0.839887  0.866728     0.819\n",
      "7           7      0.5   0.706501   0.938  0.797392  0.873706     0.752\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï Ìï®Ïàò\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# Í≤∞Í≥º Ï†ÄÏû• Î¶¨Ïä§Ìä∏\n",
    "all_results = []\n",
    "\n",
    "# Ïã§Ìóò Ï°∞Ìï© Î∞òÎ≥µ\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # ÌÖêÏÑú Î≥ÄÌôò\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # Î™®Îç∏ Ï†ïÏùò\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "        \n",
    "            trigger = 0\n",
    "\n",
    "            # ÌïôÏäµ\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Í≤ÄÏ¶ù\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold ÌÉêÏÉâ\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # ÌÖåÏä§Ìä∏\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # ÌèâÍ∑† Ï†ÄÏû•\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\nüìä Ïã§Ìóò Í≤∞Í≥º ÏöîÏïΩ:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9Í∞ú Î≥ÄÏàò, Ïä§ÏºÄÏùºÎßÅ X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ï†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: 0.9650\n",
      "‚úÖ ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎπÑÏ†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: 0.7654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# class1 Í∏∞Ï§Ä Î∂ÑÎ¶¨\n",
    "normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "# Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÌïôÏäµ(400), ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ïÏö©(60), ÌèâÍ∞ÄÏö©(200)\n",
    "train_normal, rest_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal, test_normal = train_test_split(rest_normal, test_size=200, random_state=seed)\n",
    "\n",
    "# ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞\n",
    "test_abnormal = abnormal_df.sample(n=439, random_state=seed)\n",
    "\n",
    "# ÌÖêÏÑú Î≥ÄÌôò Ìï®Ïàò\n",
    "def to_tensor(df):\n",
    "    return torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "X_train = to_tensor(train_normal)\n",
    "X_val_normal = to_tensor(val_normal)\n",
    "X_test_normal = to_tensor(test_normal)\n",
    "X_test_abnormal = to_tensor(test_abnormal)\n",
    "\n",
    "# AutoEncoder Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=5):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# Î™®Îç∏ ÏÑ§Ï†ï\n",
    "input_dim = X_train.shape[1]\n",
    "model = AutoEncoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ÌïôÏäµ\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞ (Î∞∞ÏπòÏ≤òÎ¶¨)\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# (1) validation normal ‚Üí threshold ÏÑ§Ï†ï\n",
    "recon_val = reconstruction_error(X_val_normal, model)\n",
    "threshold = torch.quantile(recon_val, 0.99)\n",
    "\n",
    "# (2) test Ï†ïÏÉÅ ÌèâÍ∞Ä\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "pred_test_normal = (recon_test_normal < threshold).int()\n",
    "acc_test_normal = pred_test_normal.sum().item() / len(pred_test_normal)\n",
    "\n",
    "# (3) test ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "pred_test_abnormal = (recon_test_abnormal >= threshold).int()\n",
    "acc_test_abnormal = pred_test_abnormal.sum().item() / len(pred_test_abnormal)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(f\"‚úÖ Ï†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: {acc_test_normal:.4f}\")\n",
    "print(f\"‚úÖ ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎπÑÏ†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: {acc_test_abnormal:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9Í∞ú Î≥ÄÏàò Ïä§ÏºÄÏùºÎßÅ O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ï†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: 0.9500\n",
      "‚úÖ ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎπÑÏ†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: 0.7745\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# class1 Í∏∞Ï§Ä Î∂ÑÎ¶¨\n",
    "normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "# Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÌïôÏäµ(400), ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ïÏö©(60), ÌèâÍ∞ÄÏö©(200)\n",
    "train_normal, rest_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal, test_normal = train_test_split(rest_normal, test_size=200, random_state=seed)\n",
    "\n",
    "# ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞\n",
    "test_abnormal = abnormal_df.sample(n=439, random_state=seed)\n",
    "\n",
    "# üîπ MinMaxScaler Ï†ÅÏö© (ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í∏∞Ï§Ä)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_np = scaler.fit_transform(train_normal)\n",
    "X_val_np = scaler.transform(val_normal)\n",
    "X_test_normal_np = scaler.transform(test_normal)\n",
    "X_test_abnormal_np = scaler.transform(test_abnormal)\n",
    "\n",
    "# ÌÖêÏÑú Î≥ÄÌôò\n",
    "def to_tensor(arr):\n",
    "    return torch.tensor(arr, dtype=torch.float32)\n",
    "\n",
    "X_train = to_tensor(X_train_np)\n",
    "X_val_normal = to_tensor(X_val_np)\n",
    "X_test_normal = to_tensor(X_test_normal_np)\n",
    "X_test_abnormal = to_tensor(X_test_abnormal_np)\n",
    "\n",
    "# AE Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# Î™®Îç∏ ÏÑ§Ï†ï\n",
    "input_dim = X_train.shape[1]\n",
    "model = AutoEncoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ÌïôÏäµ\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# (1) ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï\n",
    "recon_val = reconstruction_error(X_val_normal, model)\n",
    "threshold = torch.quantile(recon_val, 0.99)\n",
    "\n",
    "# (2) test Ï†ïÏÉÅ ÌèâÍ∞Ä\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "pred_test_normal = (recon_test_normal < threshold).int()\n",
    "acc_test_normal = pred_test_normal.sum().item() / len(pred_test_normal)\n",
    "\n",
    "# (3) test ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "pred_test_abnormal = (recon_test_abnormal >= threshold).int()\n",
    "acc_test_abnormal = pred_test_abnormal.sum().item() / len(pred_test_abnormal)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(f\"‚úÖ Ï†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: {acc_test_normal:.4f}\")\n",
    "print(f\"‚úÖ ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎπÑÏ†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: {acc_test_abnormal:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 9])\n",
      "torch.Size([60, 9])\n",
      "torch.Size([200, 9])\n",
      "torch.Size([439, 9])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape); print(X_val_normal.shape); print(X_test_normal.shape); print(X_test_abnormal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8Í∞ú Î≥ÄÏàò, Ïä§ÏºÄÏùºÎßÅ O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ï†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: 0.9650\n",
      "‚úÖ ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎπÑÏ†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: 0.7654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ÏãúÎìú Í≥†Ï†ï\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# üîπ ÏÇ¨Ïö© Î≥ÄÏàò ÏßÄÏ†ï (Temperature Ï†úÏô∏)\n",
    "feature_cols = ['IUFL', 'EUFL', 'IUFR', 'EUFR', 'IURL', 'EURL', 'IURR', 'EURR']\n",
    "\n",
    "# class1 Í∏∞Ï§Ä Î∂ÑÎ¶¨\n",
    "normal_df = final_df[final_df['class1'] == 0][feature_cols]\n",
    "abnormal_df = final_df[final_df['class1'] == 1][feature_cols]\n",
    "\n",
    "# Ï†ïÏÉÅ Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "train_normal, rest_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal, test_normal = train_test_split(rest_normal, test_size=200, random_state=seed)\n",
    "\n",
    "# ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞\n",
    "test_abnormal = abnormal_df.sample(n=439, random_state=seed)\n",
    "\n",
    "# üîπ MinMaxScaler Ï†ÅÏö© (train Í∏∞Ï§Ä)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_np = scaler.fit_transform(train_normal)\n",
    "X_val_np = scaler.transform(val_normal)\n",
    "X_test_normal_np = scaler.transform(test_normal)\n",
    "X_test_abnormal_np = scaler.transform(test_abnormal)\n",
    "\n",
    "# ÌÖêÏÑú Î≥ÄÌôò\n",
    "def to_tensor(arr):\n",
    "    return torch.tensor(arr, dtype=torch.float32)\n",
    "\n",
    "X_train = to_tensor(X_train_np)\n",
    "X_val_normal = to_tensor(X_val_np)\n",
    "X_test_normal = to_tensor(X_test_normal_np)\n",
    "X_test_abnormal = to_tensor(X_test_abnormal_np)\n",
    "\n",
    "# AE Ï†ïÏùò\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# Î™®Îç∏ ÏÑ§Ï†ï\n",
    "input_dim = X_train.shape[1]\n",
    "model = AutoEncoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ÌïôÏäµ\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# (1) threshold ÏÑ§Ï†ï\n",
    "recon_val = reconstruction_error(X_val_normal, model)\n",
    "threshold = torch.quantile(recon_val, 0.99)\n",
    "\n",
    "# (2) test Ï†ïÏÉÅ ÌèâÍ∞Ä\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "pred_test_normal = (recon_test_normal < threshold).int()\n",
    "acc_test_normal = pred_test_normal.sum().item() / len(pred_test_normal)\n",
    "\n",
    "# (3) test ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "pred_test_abnormal = (recon_test_abnormal >= threshold).int()\n",
    "acc_test_abnormal = pred_test_abnormal.sum().item() / len(pred_test_abnormal)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(f\"‚úÖ Ï†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: {acc_test_normal:.4f}\")\n",
    "print(f\"‚úÖ ÎπÑÏ†ïÏÉÅ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎπÑÏ†ïÏÉÅÏúºÎ°ú Î∂ÑÎ•òÎêú ÎπÑÏú®: {acc_test_abnormal:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia3-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
