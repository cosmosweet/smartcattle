{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/clinical_mastitis_cows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jersey      6498\n",
       "hostlene     102\n",
       "Name: Breed, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cow_ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Months after giving birth</th>\n",
       "      <th>Previous_Mastits_status</th>\n",
       "      <th>IUFL</th>\n",
       "      <th>EUFL</th>\n",
       "      <th>IUFR</th>\n",
       "      <th>EUFR</th>\n",
       "      <th>IURL</th>\n",
       "      <th>EURL</th>\n",
       "      <th>IURR</th>\n",
       "      <th>EURR</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Pain</th>\n",
       "      <th>Milk_visibility</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cow1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>180</td>\n",
       "      <td>150</td>\n",
       "      <td>180</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cow1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>180</td>\n",
       "      <td>152</td>\n",
       "      <td>185</td>\n",
       "      <td>151</td>\n",
       "      <td>180</td>\n",
       "      <td>152</td>\n",
       "      <td>181</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cow1</td>\n",
       "      <td>3</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>182</td>\n",
       "      <td>153</td>\n",
       "      <td>186</td>\n",
       "      <td>151</td>\n",
       "      <td>186</td>\n",
       "      <td>153</td>\n",
       "      <td>183</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cow1</td>\n",
       "      <td>4</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>183</td>\n",
       "      <td>155</td>\n",
       "      <td>189</td>\n",
       "      <td>155</td>\n",
       "      <td>182</td>\n",
       "      <td>155</td>\n",
       "      <td>186</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cow1</td>\n",
       "      <td>5</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>186</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>185</td>\n",
       "      <td>150</td>\n",
       "      <td>188</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cow1</td>\n",
       "      <td>6</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>182</td>\n",
       "      <td>152</td>\n",
       "      <td>182</td>\n",
       "      <td>150</td>\n",
       "      <td>181</td>\n",
       "      <td>152</td>\n",
       "      <td>181</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cow_ID  Day   Breed  Months after giving birth  Previous_Mastits_status  \\\n",
       "0   cow1    1  Jersey                          1                        0   \n",
       "1   cow1    2  Jersey                          1                        0   \n",
       "2   cow1    3  Jersey                          1                        0   \n",
       "3   cow1    4  Jersey                          1                        0   \n",
       "4   cow1    5  Jersey                          1                        0   \n",
       "5   cow1    6  Jersey                          1                        0   \n",
       "\n",
       "   IUFL  EUFL  IUFR  EUFR  IURL  EURL  IURR  EURR  Temperature  Hardness  \\\n",
       "0   150   180   150   180   150   181   150   181           43         0   \n",
       "1   152   180   152   185   151   180   152   181           42         0   \n",
       "2   152   182   153   186   151   186   153   183           41         0   \n",
       "3   155   183   155   189   155   182   155   186           40         0   \n",
       "4   150   186   150   181   150   185   150   188           41         0   \n",
       "5   152   182   152   182   150   181   152   181           40         0   \n",
       "\n",
       "   Pain  Milk_visibility  class1  \n",
       "0     0                0       0  \n",
       "1     0                0       0  \n",
       "2     0                0       0  \n",
       "3     0                0       0  \n",
       "4     0                0       0  \n",
       "5     0                0       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 변수 개수: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUFL_mean</th>\n",
       "      <th>EUFL_mean</th>\n",
       "      <th>IUFR_mean</th>\n",
       "      <th>EUFR_mean</th>\n",
       "      <th>IURL_mean</th>\n",
       "      <th>EURL_mean</th>\n",
       "      <th>IURR_mean</th>\n",
       "      <th>EURR_mean</th>\n",
       "      <th>Temperature_mean</th>\n",
       "      <th>IUFL_range</th>\n",
       "      <th>EUFL_range</th>\n",
       "      <th>IUFR_range</th>\n",
       "      <th>EUFR_range</th>\n",
       "      <th>IURL_range</th>\n",
       "      <th>EURL_range</th>\n",
       "      <th>IURR_range</th>\n",
       "      <th>EURR_range</th>\n",
       "      <th>Temperature_range</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cow_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cow1</th>\n",
       "      <td>151.833333</td>\n",
       "      <td>182.166667</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>183.833333</td>\n",
       "      <td>151.166667</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>183.333333</td>\n",
       "      <td>41.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow2</th>\n",
       "      <td>237.833333</td>\n",
       "      <td>275.500000</td>\n",
       "      <td>233.500000</td>\n",
       "      <td>276.166667</td>\n",
       "      <td>234.333333</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>238.666667</td>\n",
       "      <td>277.333333</td>\n",
       "      <td>40.833333</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow3</th>\n",
       "      <td>238.833333</td>\n",
       "      <td>276.500000</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>277.166667</td>\n",
       "      <td>235.333333</td>\n",
       "      <td>280.500000</td>\n",
       "      <td>239.666667</td>\n",
       "      <td>278.333333</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow4</th>\n",
       "      <td>183.333333</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>185.500000</td>\n",
       "      <td>215.833333</td>\n",
       "      <td>183.833333</td>\n",
       "      <td>211.333333</td>\n",
       "      <td>185.666667</td>\n",
       "      <td>213.666667</td>\n",
       "      <td>41.166667</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow5</th>\n",
       "      <td>154.333333</td>\n",
       "      <td>184.833333</td>\n",
       "      <td>154.333333</td>\n",
       "      <td>188.166667</td>\n",
       "      <td>156.833333</td>\n",
       "      <td>183.833333</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>184.666667</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IUFL_mean   EUFL_mean   IUFR_mean   EUFR_mean   IURL_mean  \\\n",
       "Cow_ID                                                               \n",
       "cow1    151.833333  182.166667  152.000000  183.833333  151.166667   \n",
       "cow2    237.833333  275.500000  233.500000  276.166667  234.333333   \n",
       "cow3    238.833333  276.500000  234.500000  277.166667  235.333333   \n",
       "cow4    183.333333  211.500000  185.500000  215.833333  183.833333   \n",
       "cow5    154.333333  184.833333  154.333333  188.166667  156.833333   \n",
       "\n",
       "         EURL_mean   IURR_mean   EURR_mean  Temperature_mean  IUFL_range  \\\n",
       "Cow_ID                                                                     \n",
       "cow1    182.500000  152.000000  183.333333         41.166667           5   \n",
       "cow2    279.500000  238.666667  277.333333         40.833333          15   \n",
       "cow3    280.500000  239.666667  278.333333         42.166667          15   \n",
       "cow4    211.333333  185.666667  213.666667         41.166667           7   \n",
       "cow5    183.833333  154.000000  184.666667         42.666667           8   \n",
       "\n",
       "        EUFL_range  IUFR_range  EUFR_range  IURL_range  EURL_range  \\\n",
       "Cow_ID                                                               \n",
       "cow1             6           5           9           5           6   \n",
       "cow2            11          10          13          15          17   \n",
       "cow3            11          10          13          15          17   \n",
       "cow4             6           8           8           6           5   \n",
       "cow5             9           9           9          10           7   \n",
       "\n",
       "        IURR_range  EURR_range  Temperature_range  class1  \n",
       "Cow_ID                                                     \n",
       "cow1             5           7                  3       0  \n",
       "cow2            20          10                  3       1  \n",
       "cow3            20          10                  6       1  \n",
       "cow4            10           5                  2       0  \n",
       "cow5            10           8                  5       1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changing_ids = ['cow10']\n",
    "\n",
    "# 사용할 컬럼\n",
    "cols = ['Cow_ID', 'Day', 'IUFL', 'EUFL', 'IUFR', 'EUFR', \n",
    "        'IURL', 'EURL', 'IURR', 'EURR', 'Temperature', 'class1']\n",
    "\n",
    "# 변화한 개체 제거\n",
    "df_filtered = df[\n",
    "    (~df['Cow_ID'].isin(changing_ids)) &\n",
    "    (df['Breed'] != 'hostlene')\n",
    "][cols].copy()\n",
    "\n",
    "# 평균과 범위 계산 대상 컬럼\n",
    "value_cols = ['IUFL', 'EUFL', 'IUFR', 'EUFR', \n",
    "              'IURL', 'EURL', 'IURR', 'EURR', 'Temperature']\n",
    "\n",
    "# (1) 평균 계산\n",
    "mean_df = df_filtered.groupby('Cow_ID')[value_cols].mean()\n",
    "mean_df.columns = [f\"{col}_mean\" for col in mean_df.columns]\n",
    "\n",
    "# (2) 범위 (최대 - 최소) 계산\n",
    "range_df = (\n",
    "    df_filtered.groupby('Cow_ID')[value_cols].max()\n",
    "    - df_filtered.groupby('Cow_ID')[value_cols].min()\n",
    ")\n",
    "range_df.columns = [f\"{col}_range\" for col in range_df.columns]\n",
    "\n",
    "# (3) class1은 마지막 날짜 기준\n",
    "class_df = (\n",
    "    df_filtered.sort_values(['Cow_ID', 'Day'])\n",
    "               .groupby('Cow_ID')['class1']\n",
    "               .last()\n",
    ")\n",
    "\n",
    "# (4) 병합\n",
    "final_df = pd.concat([mean_df, range_df], axis=1)\n",
    "final_df['class1'] = class_df\n",
    "\n",
    "# 정렬 및 인덱스 정리\n",
    "final_df = final_df.reset_index()\n",
    "final_df['Cow_ID_num'] = final_df['Cow_ID'].str.extract('(\\d+)').astype(int)\n",
    "final_df = final_df.sort_values('Cow_ID_num').drop(columns='Cow_ID_num')\n",
    "final_df = final_df.set_index('Cow_ID')\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"최종 변수 개수: {final_df.shape[1]}\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082, 19)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train_normal: 400\n",
      "✅ val_normal: 100, val_abnormal: 100\n",
      "✅ test_normal: 100, test_abnormal: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 시드 고정\n",
    "seed = 42\n",
    "\n",
    "# class1 기준 분리\n",
    "normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "# 정상: 400 train / 100 val / 100 test\n",
    "train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "remaining_for_test = remaining_normal.drop(val_normal.index)\n",
    "test_normal = remaining_for_test.sample(n=100, random_state=seed)\n",
    "\n",
    "# 비정상: 100 val / 100 test\n",
    "val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "# 확인\n",
    "print(f\"✅ train_normal: {len(train_normal)}\")\n",
    "print(f\"✅ val_normal: {len(val_normal)}, val_abnormal: {len(val_abnormal)}\")\n",
    "print(f\"✅ test_normal: {len(test_normal)}, test_abnormal: {len(test_abnormal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# DataFrame to Tensor 변환 함수\n",
    "def to_tensor(df):\n",
    "    return torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "# 텐서로 변환\n",
    "X_train = to_tensor(train_normal)\n",
    "X_val_normal = to_tensor(val_normal)\n",
    "X_val_abnormal = to_tensor(val_abnormal)\n",
    "X_test_normal = to_tensor(test_normal)\n",
    "X_test_abnormal = to_tensor(test_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32989\n",
      "📌 Confusion Matrix (기준: 실제=행, 예측=열, class=1 비정상 기준)\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "Precision: 0.9796\n",
      "Recall:    0.9600\n",
      "F1 Score:  0.9697\n",
      "Accuracy:  0.9700\n",
      "Best Threshold by F1: 81.600266\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=14):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# 재구성 오차 계산 함수\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# 모델 초기화\n",
    "model = AutoEncoder(input_dim=18)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "n_epochs = 100000\n",
    "patience = 10000\n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # early stopping용 검증 로스\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val_normal)\n",
    "        val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# 최적 모델 로드\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# 검증 데이터 재구성 오차\n",
    "recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "y_val_true = torch.cat([\n",
    "    torch.zeros_like(recon_val_normal),\n",
    "    torch.ones_like(recon_val_abnormal)\n",
    "])\n",
    "\n",
    "# F1 기준 최적 임계값 찾기\n",
    "thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "best_f1 = 0\n",
    "best_threshold = None\n",
    "for t in thresholds:\n",
    "    y_pred = (recon_val_all >= t).int()\n",
    "    f1 = f1_score(y_val_true.numpy(), y_pred.numpy())\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "y_test_true = torch.cat([\n",
    "    torch.zeros_like(recon_test_normal),\n",
    "    torch.ones_like(recon_test_abnormal)\n",
    "])\n",
    "y_test_pred = (recon_test_all >= best_threshold).int()\n",
    "\n",
    "# 평가 지표 계산 (비정상 class=1을 기준으로)\n",
    "cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "accuracy = accuracy_score(y_test_true, y_test_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"📌 Confusion Matrix (기준: 실제=행, 예측=열, class=1 비정상 기준)\")\n",
    "print(cm)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Best Threshold by F1: {best_threshold:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23696\n",
      "📌 Confusion Matrix (기준: 실제=행, 예측=열, class=1 비정상 기준)\n",
      "[[64 36]\n",
      " [ 4 96]]\n",
      "Precision: 0.7273\n",
      "Recall:    0.9600\n",
      "F2 Score:  0.9023\n",
      "Accuracy:  0.8000\n",
      "Best Threshold by F2: 87.064911\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "seed = 45\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=7):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# 재구성 오차 계산 함수\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# 모델 초기화\n",
    "model = AutoEncoder(input_dim=18)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "n_epochs = 100000\n",
    "patience = 10000\n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # early stopping용 검증 로스\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val_normal)\n",
    "        val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# 최적 모델 로드\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# 검증 데이터 재구성 오차\n",
    "recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "y_val_true = torch.cat([\n",
    "    torch.zeros_like(recon_val_normal),\n",
    "    torch.ones_like(recon_val_abnormal)\n",
    "])\n",
    "\n",
    "# F2 기준 최적 임계값 찾기\n",
    "thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "best_f2 = 0\n",
    "best_threshold = None\n",
    "for t in thresholds:\n",
    "    y_pred = (recon_val_all >= t).int()\n",
    "    f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "    if f2 > best_f2:\n",
    "        best_f2 = f2\n",
    "        best_threshold = t\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "y_test_true = torch.cat([\n",
    "    torch.zeros_like(recon_test_normal),\n",
    "    torch.ones_like(recon_test_abnormal)\n",
    "])\n",
    "y_test_pred = (recon_test_all >= best_threshold).int()\n",
    "\n",
    "# 평가 지표 계산 (비정상 class=1을 기준으로)\n",
    "cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "accuracy = accuracy_score(y_test_true, y_test_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"📌 Confusion Matrix (기준: 실제=행, 예측=열, class=1 비정상 기준)\")\n",
    "print(cm)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F2 Score:  {fbeta_score(y_test_true.numpy(), y_test_pred.numpy(), beta=2):.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Best Threshold by F2: {best_threshold:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7/2 피드백"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[96  4]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[89 11]\n",
      " [13 87]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[96  4]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [16 84]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[96  4]\n",
      " [19 81]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[100   0]\n",
      " [ 10  90]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[92  8]\n",
      " [16 84]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[98  2]\n",
      " [19 81]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[97  3]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[89 11]\n",
      " [13 87]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[96  4]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[93  7]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[99  1]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[96  4]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[96  4]\n",
      " [19 81]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 9 91]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[98  2]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[97  3]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[98  2]\n",
      " [19 81]]\n",
      "\n",
      "📊 실험 결과 요약:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.949767   0.896  0.921953  0.906171     0.924\n",
      "1           4      0.3   0.960317   0.876  0.915946  0.891494     0.920\n",
      "2           4      0.4   0.964239   0.866  0.912021  0.883743     0.917\n",
      "3           4      0.5   0.962550   0.862  0.909041  0.880126     0.914\n",
      "4           7      0.2   0.951847   0.896  0.922913  0.906538     0.925\n",
      "5           7      0.3   0.956543   0.886  0.919798  0.899190     0.923\n",
      "6           7      0.4   0.967053   0.878  0.919904  0.894197     0.924\n",
      "7           7      0.5   0.971282   0.872  0.918381  0.889859     0.923\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시드 고정 함수\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# 재구성 오차 계산\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# 결과 저장 리스트\n",
    "all_results = []\n",
    "\n",
    "# 실험 조합 반복\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # 데이터 분할\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # 텐서 변환\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # 모델 정의\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "            trigger = 0\n",
    "\n",
    "            # 학습\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 검증\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold 탐색\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # 테스트\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # 평균 저장\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# 최종 결과 출력\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\n📊 실험 결과 요약:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "예측된 이상치 수: 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUFL_mean</th>\n",
       "      <th>EUFL_mean</th>\n",
       "      <th>IUFR_mean</th>\n",
       "      <th>EUFR_mean</th>\n",
       "      <th>IURL_mean</th>\n",
       "      <th>EURL_mean</th>\n",
       "      <th>IURR_mean</th>\n",
       "      <th>EURR_mean</th>\n",
       "      <th>Temperature_mean</th>\n",
       "      <th>IUFL_range</th>\n",
       "      <th>...</th>\n",
       "      <th>IUFR_range</th>\n",
       "      <th>EUFR_range</th>\n",
       "      <th>IURL_range</th>\n",
       "      <th>EURL_range</th>\n",
       "      <th>IURR_range</th>\n",
       "      <th>EURR_range</th>\n",
       "      <th>Temperature_range</th>\n",
       "      <th>recon_error</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>235.666667</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>234.166667</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>263.666667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3138.750977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>263.666667</td>\n",
       "      <td>297.666667</td>\n",
       "      <td>263.666667</td>\n",
       "      <td>295.166667</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>297.666667</td>\n",
       "      <td>263.333333</td>\n",
       "      <td>297.333333</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3697.348633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>235.500000</td>\n",
       "      <td>276.833333</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>235.333333</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>237.666667</td>\n",
       "      <td>277.333333</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4968.123047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>186.833333</td>\n",
       "      <td>305.833333</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>153.833333</td>\n",
       "      <td>185.333333</td>\n",
       "      <td>154.500000</td>\n",
       "      <td>185.333333</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4575.005859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>237.333333</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>356.166667</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>275.833333</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>49.833333</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4994.061523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>309.166667</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>240.666667</td>\n",
       "      <td>282.833333</td>\n",
       "      <td>239.500000</td>\n",
       "      <td>281.833333</td>\n",
       "      <td>241.166667</td>\n",
       "      <td>279.833333</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4238.732422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>305.833333</td>\n",
       "      <td>357.333333</td>\n",
       "      <td>260.333333</td>\n",
       "      <td>283.166667</td>\n",
       "      <td>260.500000</td>\n",
       "      <td>281.166667</td>\n",
       "      <td>258.500000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5531.837402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>302.666667</td>\n",
       "      <td>356.833333</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>277.166667</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>275.833333</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>276.333333</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5160.001953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>239.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>240.333333</td>\n",
       "      <td>278.833333</td>\n",
       "      <td>308.666667</td>\n",
       "      <td>356.666667</td>\n",
       "      <td>237.666667</td>\n",
       "      <td>277.166667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3926.436523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>230.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>231.333333</td>\n",
       "      <td>269.833333</td>\n",
       "      <td>299.666667</td>\n",
       "      <td>347.666667</td>\n",
       "      <td>228.666667</td>\n",
       "      <td>268.166667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3581.935303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IUFL_mean   EUFL_mean   IUFR_mean   EUFR_mean   IURL_mean   EURL_mean  \\\n",
       "44   235.666667  267.000000  236.000000  264.500000  234.166667  265.000000   \n",
       "46   263.666667  297.666667  263.666667  295.166667  262.000000  297.666667   \n",
       "101  235.500000  276.833333  306.000000  356.000000  235.333333  276.000000   \n",
       "103  154.000000  186.833333  305.833333  358.000000  153.833333  185.333333   \n",
       "104  237.333333  276.000000  307.666667  356.166667  234.500000  275.833333   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "194  309.166667  360.000000  240.666667  282.833333  239.500000  281.833333   \n",
       "195  305.833333  357.333333  260.333333  283.166667  260.500000  281.166667   \n",
       "196  302.666667  356.833333  236.500000  277.166667  236.500000  275.833333   \n",
       "198  239.000000  276.000000  240.333333  278.833333  308.666667  356.666667   \n",
       "199  230.000000  267.000000  231.333333  269.833333  299.666667  347.666667   \n",
       "\n",
       "      IURR_mean   EURR_mean  Temperature_mean  IUFL_range  ...  IUFR_range  \\\n",
       "44   124.500000  263.666667         43.000000          10  ...           9   \n",
       "46   263.333333  297.333333         43.000000           9  ...           6   \n",
       "101  237.666667  277.333333         50.000000          10  ...           9   \n",
       "103  154.500000  185.333333         49.000000           7  ...          10   \n",
       "104  238.000000  279.000000         49.833333          10  ...          10   \n",
       "..          ...         ...               ...         ...  ...         ...   \n",
       "194  241.166667  279.833333         43.000000           7  ...          10   \n",
       "195  258.500000  282.000000         55.500000          10  ...           8   \n",
       "196  234.500000  276.333333         56.000000           6  ...           8   \n",
       "198  237.666667  277.166667         43.000000          10  ...          10   \n",
       "199  228.666667  268.166667         43.000000          10  ...          10   \n",
       "\n",
       "     EUFR_range  IURL_range  EURL_range  IURR_range  EURR_range  \\\n",
       "44            5          10           8           8           7   \n",
       "46            6           6           9           9          10   \n",
       "101           8          10           8           7           8   \n",
       "103           9          10           5           8           7   \n",
       "104           7           6           7          10          10   \n",
       "..          ...         ...         ...         ...         ...   \n",
       "194           9          10           9          10           6   \n",
       "195           9           9           9          10          10   \n",
       "196          10          10           8           3           9   \n",
       "198           8           9          10          10          10   \n",
       "199           8           9          10          10          10   \n",
       "\n",
       "     Temperature_range  recon_error  true_label  pred_label  \n",
       "44                   0  3138.750977         0.0           1  \n",
       "46                   0  3697.348633         0.0           1  \n",
       "101                  0  4968.123047         1.0           1  \n",
       "103                  0  4575.005859         1.0           1  \n",
       "104                  1  4994.061523         1.0           1  \n",
       "..                 ...          ...         ...         ...  \n",
       "194                  0  4238.732422         1.0           1  \n",
       "195                  2  5531.837402         1.0           1  \n",
       "196                  0  5160.001953         1.0           1  \n",
       "198                  0  3926.436523         1.0           1  \n",
       "199                  0  3581.935303         1.0           1  \n",
       "\n",
       "[83 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 재구성 오차 계산\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "\n",
    "# 실제 라벨\n",
    "y_test_true = torch.cat([\n",
    "    torch.zeros_like(recon_test_normal),\n",
    "    torch.ones_like(recon_test_abnormal)\n",
    "])\n",
    "\n",
    "# 전체 테스트 재구성오차\n",
    "recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "# 전체 테스트 데이터프레임 구성\n",
    "test_all_df = pd.concat([test_normal, test_abnormal], axis=0).reset_index(drop=True)\n",
    "test_all_df['recon_error'] = recon_test_all.cpu().numpy()\n",
    "test_all_df['true_label'] = y_test_true.cpu().numpy()\n",
    "test_all_df['pred_label'] = y_test_pred.cpu().numpy()\n",
    "\n",
    "# ✅ 이상치로 예측된 케이스만 보기\n",
    "anomalies = test_all_df[test_all_df['pred_label'] == 1]\n",
    "print(f\"\\n예측된 이상치 수: {len(anomalies)}\")\n",
    "display(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[69 31]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[71 29]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[69 31]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[90 10]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[72 28]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[46 54]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[76 24]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[49 51]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[42 58]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[76 24]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[55 45]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[89 11]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[91  9]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[95  5]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[69 31]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[95  5]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[92  8]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[90 10]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [12 88]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[44 56]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[46 54]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[90 10]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[  1  99]\n",
      " [  0 100]]\n",
      "\n",
      "📊 실험 결과 요약:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.790932   0.940  0.845848  0.894903     0.806\n",
      "1           4      0.3   0.777039   0.932  0.835756  0.886310     0.796\n",
      "2           4      0.4   0.712237   0.948  0.801026  0.878658     0.744\n",
      "3           4      0.5   0.710910   0.932  0.792787  0.865965     0.737\n",
      "4           7      0.2   0.846395   0.942  0.877643  0.909670     0.845\n",
      "5           7      0.3   0.832068   0.940  0.868068  0.904262     0.832\n",
      "6           7      0.4   0.789624   0.952  0.848944  0.902495     0.805\n",
      "7           7      0.5   0.729367   0.936  0.803022  0.871979     0.747\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시드 고정 함수\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# 재구성 오차 계산\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# 결과 저장 리스트\n",
    "all_results = []\n",
    "\n",
    "# 실험 조합 반복\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # 데이터 분할\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # 텐서 변환\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # 모델 정의\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "            trigger = 0\n",
    "\n",
    "            # 학습\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 검증\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold 탐색\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # 테스트\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # 평균 저장\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# 최종 결과 출력\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\n📊 실험 결과 요약:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[92  8]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[93  7]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[97  3]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[91  9]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[98  2]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[35 65]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[95  5]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[91  9]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[95  5]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[95  5]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[92  8]\n",
      " [15 85]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[87 13]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "📊 실험 결과 요약:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.946889   0.890  0.917297  0.900663     0.920\n",
      "1           4      0.3   0.951614   0.868  0.907728  0.883434     0.912\n",
      "2           4      0.4   0.933584   0.874  0.902650  0.885204     0.906\n",
      "3           4      0.5   0.764277   0.942  0.830876  0.890141     0.792\n",
      "4           7      0.2   0.951768   0.902  0.925683  0.911206     0.928\n",
      "5           7      0.3   0.895404   0.900  0.890064  0.893682     0.880\n",
      "6           7      0.4   0.882445   0.884  0.875693  0.878352     0.866\n",
      "7           7      0.5   0.811183   0.928  0.856323  0.895013     0.835\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시드 고정 함수\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# 재구성 오차 계산\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# 결과 저장 리스트\n",
    "all_results = []\n",
    "\n",
    "# 실험 조합 반복\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # 데이터 분할\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # 텐서 변환\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # 모델 정의\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "        \n",
    "            trigger = 0\n",
    "\n",
    "            # 학습\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 검증\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold 탐색\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # 테스트\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # 평균 저장\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# 최종 결과 출력\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\n📊 실험 결과 요약:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== latent_dim=4, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[94  6]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[45 55]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[38 62]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[92  8]\n",
      " [10 90]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[94  6]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[39 61]\n",
      " [ 5 95]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[46 54]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[93  7]\n",
      " [14 86]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[95  5]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[45 55]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[91  9]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=4, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[96  4]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[35 65]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.2 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[82 18]\n",
      " [13 87]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[99  1]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[94  6]\n",
      " [17 83]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.3 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[97  3]\n",
      " [ 6 94]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[90 10]\n",
      " [17 83]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[95  5]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.4 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[94  6]\n",
      " [18 82]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[91  9]\n",
      " [18 82]]\n",
      "\n",
      "=== latent_dim=7, dropout=0.5 ===\n",
      "\n",
      "[Seed 42] Confusion Matrix\n",
      "[[98  2]\n",
      " [11 89]]\n",
      "\n",
      "[Seed 43] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 8 92]]\n",
      "\n",
      "[Seed 44] Confusion Matrix\n",
      "[[47 53]\n",
      " [ 3 97]]\n",
      "\n",
      "[Seed 45] Confusion Matrix\n",
      "[[43 57]\n",
      " [ 7 93]]\n",
      "\n",
      "[Seed 46] Confusion Matrix\n",
      "[[48 52]\n",
      " [ 2 98]]\n",
      "\n",
      "📊 실험 결과 요약:\n",
      "   latent_dim  dropout  precision  recall        f1        f2  accuracy\n",
      "0           4      0.2   0.805608   0.916  0.846373  0.883406     0.821\n",
      "1           4      0.3   0.811602   0.906  0.843593  0.876100     0.820\n",
      "2           4      0.4   0.806275   0.904  0.842358  0.875228     0.821\n",
      "3           4      0.5   0.696009   0.958  0.798725  0.884865     0.748\n",
      "4           7      0.2   0.869999   0.902  0.878830  0.890486     0.867\n",
      "5           7      0.3   0.810789   0.898  0.839841  0.870051     0.817\n",
      "6           7      0.4   0.815661   0.892  0.839887  0.866728     0.819\n",
      "7           7      0.5   0.706501   0.938  0.797392  0.873706     0.752\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시드 고정 함수\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# AutoEncoder 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=18, latent_dim=4, dropout_rate=0.3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# 재구성 오차 계산\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# 결과 저장 리스트\n",
    "all_results = []\n",
    "\n",
    "# 실험 조합 반복\n",
    "for latent_dim in [4, 7]:\n",
    "    for dropout_rate in [0.2, 0.3, 0.4, 0.5]:\n",
    "        precisions, recalls, f1s, f2s, accs = [], [], [], [], []\n",
    "        print(f\"\\n=== latent_dim={latent_dim}, dropout={dropout_rate} ===\")\n",
    "        for seed in range(42, 47):\n",
    "            set_seed(seed)\n",
    "\n",
    "            # 데이터 분할\n",
    "            normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "            abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "            train_normal, remaining_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "            val_normal = remaining_normal.sample(n=100, random_state=seed)\n",
    "            test_normal = remaining_normal.drop(val_normal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            val_abnormal = abnormal_df.sample(n=100, random_state=seed)\n",
    "            test_abnormal = abnormal_df.drop(val_abnormal.index).sample(n=100, random_state=seed)\n",
    "\n",
    "            # 텐서 변환\n",
    "            X_train = torch.tensor(train_normal.values, dtype=torch.float32)\n",
    "            X_val_normal = torch.tensor(val_normal.values, dtype=torch.float32)\n",
    "            X_val_abnormal = torch.tensor(val_abnormal.values, dtype=torch.float32)\n",
    "            X_test_normal = torch.tensor(test_normal.values, dtype=torch.float32)\n",
    "            X_test_abnormal = torch.tensor(test_abnormal.values, dtype=torch.float32)\n",
    "\n",
    "            # 모델 정의\n",
    "            model = AutoEncoder(input_dim=18, latent_dim=latent_dim, dropout_rate=dropout_rate)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "            best_loss = float('inf')\n",
    "            patience = 10000\n",
    "        \n",
    "            trigger = 0\n",
    "\n",
    "            # 학습\n",
    "            for epoch in range(100000):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_train)\n",
    "                loss = criterion(output, X_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 검증\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_output = model(X_val_normal)\n",
    "                    val_loss = criterion(val_output, X_val_normal)\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "                    trigger = 0\n",
    "                else:\n",
    "                    trigger += 1\n",
    "                    if trigger >= patience:\n",
    "                        break\n",
    "\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # threshold 탐색\n",
    "            recon_val_normal = reconstruction_error(X_val_normal, model)\n",
    "            recon_val_abnormal = reconstruction_error(X_val_abnormal, model)\n",
    "            recon_val_all = torch.cat([recon_val_normal, recon_val_abnormal])\n",
    "            y_val_true = torch.cat([\n",
    "                torch.zeros_like(recon_val_normal),\n",
    "                torch.ones_like(recon_val_abnormal)\n",
    "            ])\n",
    "            thresholds = torch.linspace(recon_val_all.min(), recon_val_all.max(), steps=200)\n",
    "            best_f2, best_th = 0, None\n",
    "            for t in thresholds:\n",
    "                y_pred = (recon_val_all >= t).int()\n",
    "                f2 = fbeta_score(y_val_true.numpy(), y_pred.numpy(), beta=2, pos_label=1)\n",
    "                if f2 > best_f2:\n",
    "                    best_f2, best_th = f2, t\n",
    "\n",
    "            # 테스트\n",
    "            recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "            recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "            recon_test_all = torch.cat([recon_test_normal, recon_test_abnormal])\n",
    "            y_test_true = torch.cat([\n",
    "                torch.zeros_like(recon_test_normal),\n",
    "                torch.ones_like(recon_test_abnormal)\n",
    "            ])\n",
    "            y_test_pred = (recon_test_all >= best_th).int()\n",
    "\n",
    "            cm = confusion_matrix(y_test_true, y_test_pred, labels=[0, 1])\n",
    "            precision = precision_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            recall = recall_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            f1 = f1_score(y_test_true, y_test_pred, pos_label=1)\n",
    "            acc = accuracy_score(y_test_true, y_test_pred)\n",
    "            f2 = fbeta_score(y_test_true, y_test_pred, beta=2, pos_label=1)\n",
    "\n",
    "            print(f\"\\n[Seed {seed}] Confusion Matrix\\n{cm}\")\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            f2s.append(f2)\n",
    "            accs.append(acc)\n",
    "\n",
    "        # 평균 저장\n",
    "        all_results.append({\n",
    "            'latent_dim': latent_dim,\n",
    "            'dropout': dropout_rate,\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'f1': np.mean(f1s),\n",
    "            'f2': np.mean(f2s),\n",
    "            'accuracy': np.mean(accs)\n",
    "        })\n",
    "\n",
    "# 최종 결과 출력\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"\\n📊 실험 결과 요약:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9개 변수, 스케일링 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정상 평가 데이터에서 정상으로 분류된 비율: 0.9650\n",
      "✅ 비정상 평가 데이터에서 비정상으로 분류된 비율: 0.7654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 시드 고정\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# class1 기준 분리\n",
    "normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "# 정상 데이터에서 학습(400), 임계값 설정용(60), 평가용(200)\n",
    "train_normal, rest_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal, test_normal = train_test_split(rest_normal, test_size=200, random_state=seed)\n",
    "\n",
    "# 비정상 평가 데이터\n",
    "test_abnormal = abnormal_df.sample(n=439, random_state=seed)\n",
    "\n",
    "# 텐서 변환 함수\n",
    "def to_tensor(df):\n",
    "    return torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "X_train = to_tensor(train_normal)\n",
    "X_val_normal = to_tensor(val_normal)\n",
    "X_test_normal = to_tensor(test_normal)\n",
    "X_test_abnormal = to_tensor(test_abnormal)\n",
    "\n",
    "# AutoEncoder 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=5):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# 모델 설정\n",
    "input_dim = X_train.shape[1]\n",
    "model = AutoEncoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 재구성 오차 계산 (배치처리)\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# (1) validation normal → threshold 설정\n",
    "recon_val = reconstruction_error(X_val_normal, model)\n",
    "threshold = torch.quantile(recon_val, 0.99)\n",
    "\n",
    "# (2) test 정상 평가\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "pred_test_normal = (recon_test_normal < threshold).int()\n",
    "acc_test_normal = pred_test_normal.sum().item() / len(pred_test_normal)\n",
    "\n",
    "# (3) test 비정상 평가\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "pred_test_abnormal = (recon_test_abnormal >= threshold).int()\n",
    "acc_test_abnormal = pred_test_abnormal.sum().item() / len(pred_test_abnormal)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"✅ 정상 평가 데이터에서 정상으로 분류된 비율: {acc_test_normal:.4f}\")\n",
    "print(f\"✅ 비정상 평가 데이터에서 비정상으로 분류된 비율: {acc_test_abnormal:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9개 변수 스케일링 O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정상 평가 데이터에서 정상으로 분류된 비율: 0.9500\n",
      "✅ 비정상 평가 데이터에서 비정상으로 분류된 비율: 0.7745\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 시드 고정\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# class1 기준 분리\n",
    "normal_df = final_df[final_df['class1'] == 0].drop(columns='class1')\n",
    "abnormal_df = final_df[final_df['class1'] == 1].drop(columns='class1')\n",
    "\n",
    "# 정상 데이터에서 학습(400), 임계값 설정용(60), 평가용(200)\n",
    "train_normal, rest_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal, test_normal = train_test_split(rest_normal, test_size=200, random_state=seed)\n",
    "\n",
    "# 비정상 평가 데이터\n",
    "test_abnormal = abnormal_df.sample(n=439, random_state=seed)\n",
    "\n",
    "# 🔹 MinMaxScaler 적용 (학습 데이터 기준)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_np = scaler.fit_transform(train_normal)\n",
    "X_val_np = scaler.transform(val_normal)\n",
    "X_test_normal_np = scaler.transform(test_normal)\n",
    "X_test_abnormal_np = scaler.transform(test_abnormal)\n",
    "\n",
    "# 텐서 변환\n",
    "def to_tensor(arr):\n",
    "    return torch.tensor(arr, dtype=torch.float32)\n",
    "\n",
    "X_train = to_tensor(X_train_np)\n",
    "X_val_normal = to_tensor(X_val_np)\n",
    "X_test_normal = to_tensor(X_test_normal_np)\n",
    "X_test_abnormal = to_tensor(X_test_abnormal_np)\n",
    "\n",
    "# AE 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# 모델 설정\n",
    "input_dim = X_train.shape[1]\n",
    "model = AutoEncoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 재구성 오차 계산\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# (1) 임계값 설정\n",
    "recon_val = reconstruction_error(X_val_normal, model)\n",
    "threshold = torch.quantile(recon_val, 0.99)\n",
    "\n",
    "# (2) test 정상 평가\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "pred_test_normal = (recon_test_normal < threshold).int()\n",
    "acc_test_normal = pred_test_normal.sum().item() / len(pred_test_normal)\n",
    "\n",
    "# (3) test 비정상 평가\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "pred_test_abnormal = (recon_test_abnormal >= threshold).int()\n",
    "acc_test_abnormal = pred_test_abnormal.sum().item() / len(pred_test_abnormal)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"✅ 정상 평가 데이터에서 정상으로 분류된 비율: {acc_test_normal:.4f}\")\n",
    "print(f\"✅ 비정상 평가 데이터에서 비정상으로 분류된 비율: {acc_test_abnormal:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 9])\n",
      "torch.Size([60, 9])\n",
      "torch.Size([200, 9])\n",
      "torch.Size([439, 9])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape); print(X_val_normal.shape); print(X_test_normal.shape); print(X_test_abnormal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8개 변수, 스케일링 O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정상 평가 데이터에서 정상으로 분류된 비율: 0.9650\n",
      "✅ 비정상 평가 데이터에서 비정상으로 분류된 비율: 0.7654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 시드 고정\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# 🔹 사용 변수 지정 (Temperature 제외)\n",
    "feature_cols = ['IUFL', 'EUFL', 'IUFR', 'EUFR', 'IURL', 'EURL', 'IURR', 'EURR']\n",
    "\n",
    "# class1 기준 분리\n",
    "normal_df = final_df[final_df['class1'] == 0][feature_cols]\n",
    "abnormal_df = final_df[final_df['class1'] == 1][feature_cols]\n",
    "\n",
    "# 정상 데이터 분할\n",
    "train_normal, rest_normal = train_test_split(normal_df, train_size=400, random_state=seed)\n",
    "val_normal, test_normal = train_test_split(rest_normal, test_size=200, random_state=seed)\n",
    "\n",
    "# 비정상 평가 데이터\n",
    "test_abnormal = abnormal_df.sample(n=439, random_state=seed)\n",
    "\n",
    "# 🔹 MinMaxScaler 적용 (train 기준)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_np = scaler.fit_transform(train_normal)\n",
    "X_val_np = scaler.transform(val_normal)\n",
    "X_test_normal_np = scaler.transform(test_normal)\n",
    "X_test_abnormal_np = scaler.transform(test_abnormal)\n",
    "\n",
    "# 텐서 변환\n",
    "def to_tensor(arr):\n",
    "    return torch.tensor(arr, dtype=torch.float32)\n",
    "\n",
    "X_train = to_tensor(X_train_np)\n",
    "X_val_normal = to_tensor(X_val_np)\n",
    "X_test_normal = to_tensor(X_test_normal_np)\n",
    "X_test_abnormal = to_tensor(X_test_abnormal_np)\n",
    "\n",
    "# AE 정의\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "# 모델 설정\n",
    "input_dim = X_train.shape[1]\n",
    "model = AutoEncoder(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, X_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 재구성 오차 계산\n",
    "def reconstruction_error(x, model, batch_size=128):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            recon = model(x_batch)\n",
    "            err = torch.mean((x_batch - recon) ** 2, dim=1)\n",
    "            errors.append(err)\n",
    "    return torch.cat(errors)\n",
    "\n",
    "# (1) threshold 설정\n",
    "recon_val = reconstruction_error(X_val_normal, model)\n",
    "threshold = torch.quantile(recon_val, 0.99)\n",
    "\n",
    "# (2) test 정상 평가\n",
    "recon_test_normal = reconstruction_error(X_test_normal, model)\n",
    "pred_test_normal = (recon_test_normal < threshold).int()\n",
    "acc_test_normal = pred_test_normal.sum().item() / len(pred_test_normal)\n",
    "\n",
    "# (3) test 비정상 평가\n",
    "recon_test_abnormal = reconstruction_error(X_test_abnormal, model)\n",
    "pred_test_abnormal = (recon_test_abnormal >= threshold).int()\n",
    "acc_test_abnormal = pred_test_abnormal.sum().item() / len(pred_test_abnormal)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"✅ 정상 평가 데이터에서 정상으로 분류된 비율: {acc_test_normal:.4f}\")\n",
    "print(f\"✅ 비정상 평가 데이터에서 비정상으로 분류된 비율: {acc_test_abnormal:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia3-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
